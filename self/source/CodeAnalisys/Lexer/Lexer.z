type Lexer {
  source: *str,
  idx: usize,

  fn addToken(&self: Lexer, token: Token) {
    tokens.push(token)
  }

  fn cur(self: Lexer): chr {
    (*self.source)[self.idx]
  }

  fn eatComments(&self: Lexer) {

  }

  fn collectNumber(&self: Lexer):  {

  }

  fn advance(&self: Lexer) {
    self.idx++
  }

  fn nxt(self: Lexer): chr {
    const nxtidx = self.idx + 1
    const source = (*self.source)
    
    if nxtidx < source.len { source[nxtidx] } else { '\0' }
  }

  fn reachedEof(self: Lexer): bool {
    self.idx >= (*self.source).len
  }

  fn collectPlusPlus(&self: Lexer) {
    self.advance()
    Token.from(.plusplus, "++", TokenPosition.from(self.idx self.idx))
  }

  fn nextToken(&self: Lexer): Token {
    self.eatComments()

    if self.reachedEof()

    const cur = self.cur()
    const nxt = self.nxt()

    const token = switch cur {
      '0'..'9'           { self.collectNumber()     }
      'a'..'z', 'A'..'Z' { self.collectIdentifier() }
      '\''               { self.collectChar()       }
      '"'                { self.collectStr()        }

      '+' and nxt == '+' { self.collectPlusPlus() }
      else               { Token.bad(cur, self.idx) }
    }
    
    self.advance()

    token
  }

  pub fn lex(source: str): List[Token] {
    var lexer = new Lexer { source: alloc!(source) }
    var tokens = List.create[Token]()

    while lexer.reachedEof() {
      tokens.push(lexer.nextToken())
    }

    tokens
  }
}